import os
import copy
import numpy as np

import gym
from gym import error, spaces
from gym.utils import seeding

try:
    import mujoco_py
except ImportError as e:
    raise error.DependencyNotInstalled("{}. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)".format(e))

DEFAULT_SIZE = 500


class RobotEnv(gym.GoalEnv):

    def __init__(self, model_path, initial_qpos, n_actions, n_substeps):
        if model_path.startswith('/'):
            fullpath = model_path
        else:
            fullpath = os.path.join(os.path.dirname(__file__), 'assets', model_path)
        if not os.path.exists(fullpath):
            raise IOError('File {} does not exist'.format(fullpath))

        model = mujoco_py.load_model_from_path(fullpath)
        self.sim = mujoco_py.MjSim(model, nsubsteps=n_substeps)
        self.viewer = None
        self._viewers = {}

        self.metadata = {
            'render.modes': ['human', 'rgb_array'],
            'video.frames_per_second': int(np.round(1.0 / self.dt))
        }

        self.seed()
        self._env_setup(initial_qpos=initial_qpos)
        self.initial_state = copy.deepcopy(self.sim.get_state())

        self.goal = self._sample_goal()
        obs = self._get_obs()
        self.action_space = spaces.Box(-1., 1., shape=(n_actions,), dtype='float32')
        self.observation_space = spaces.Dict(dict(
            desired_goal=spaces.Box(-np.inf, np.inf, shape=obs['achieved_goal'].shape, dtype='float32'),
            achieved_goal=spaces.Box(-np.inf, np.inf, shape=obs['achieved_goal'].shape, dtype='float32'),
            observation=spaces.Box(-np.inf, np.inf, shape=obs['observation'].shape, dtype='float32'),
        ))

    @property
    def dt(self):
        return self.sim.model.opt.timestep * self.sim.nsubsteps

    # Env methods
    # ----------------------------

    def seed(self, seed=None):
        self.np_random, seed = seeding.np_random(seed)
        return [seed]

    def step(self, action):
        action = np.clip(action, self.action_space.low, self.action_space.high)
        self._set_action(action)
        self.sim.step()
        self._step_callback()
        obs = self._get_obs()

        done = False
        info = {
            'is_success': self._is_success(obs['achieved_goal'], self.goal),
        }
        reward = self.compute_reward(obs['achieved_goal'], self.goal, info)
        return obs, reward, done, info

    def reset(self):
        # Attempt to reset the simulator. With randomized initial conditions,
        # it is possible to get into a state with numerical issues (e.g. due to
        # penetration or gimbal lock) or we may not achieve an initial
        # condition (e.g. an object is within the hand). In this case, just
        # keep randomizing until we eventually achieve a valid initial
        # configuration.
        did_reset_sim = False
        while not did_reset_sim:
            did_reset_sim = self._reset_sim()
        self.goal = self._sample_goal().copy()
        obs = self._get_obs()
        return obs

    def close(self):
        if self.viewer is not None:
            # self.viewer.finish()
            self.viewer = None
            self._viewers = {}

    def render(self, mode='human', width=DEFAULT_SIZE, height=DEFAULT_SIZE):
        self._render_callback()
        if mode == 'rgb_array':
            self._get_viewer(mode).render(width, height)
            # window size used for old mujoco-py:
            data = self._get_viewer(mode).read_pixels(width, height, depth=False)
            # original image is upside-down, so flip it
            return data[::-1, :, :]
        # [[[ bbeckman --- human mode is ignoring width and height. The ignoring
        # happens way down deep in the mujoco layer. mujoco_py.MjViewer ignores
        # the width and height from here and opens a window full-screen. ]]]
        elif mode == 'human':
            self._get_viewer(mode).render()

    def _get_viewer(self, mode):
        self.viewer = self._viewers.get(mode)
        if self.viewer is None:
            if mode == 'human':
                self.viewer = mujoco_py.MjViewer(self.sim)
            elif mode == 'rgb_array':
                self.viewer = mujoco_py.MjRenderContextOffscreen(self.sim, device_id=-1)
            self._viewer_setup()
            self._viewers[mode] = self.viewer
        return self.viewer

    # Extension methods
    # ----------------------------

    def _reset_sim(self):
        """Resets a simulation and indicates whether or not it was successful.
        If a reset was unsuccessful (e.g. if a randomized state caused an error in the
        simulation), this method should indicate such a failure by returning False.
        In such a case, this method will be called again to attempt a the reset again.
        """
        self.sim.set_state(self.initial_state)
        self.sim.forward()
        return True

    def _get_obs(self):
        """Returns the observation.
        """
        raise NotImplementedError()

    def _set_action(self, action):
        """Applies the given action to the simulation.
        """
        raise NotImplementedError()

    def _is_success(self, achieved_goal, desired_goal):
        """Indicates whether or not the achieved goal successfully achieved the desired goal.
        """
        raise NotImplementedError()

    def _sample_goal(self):
        """Samples a new goal and returns it.
        """
        raise NotImplementedError()

    def _env_setup(self, initial_qpos):
        """Initial configuration of the environment. Can be used to configure initial state
        and extract information from the simulation.
        """
        pass

    def _viewer_setup(self):
        """Initial configuration of the viewer. Can be used to set the camera position,
        for example.
        """
        pass

    def _render_callback(self):
        """A custom callback that is called before rendering. Can be used
        to implement custom visualizations.
        """
        pass

    def _step_callback(self):
        """A custom callback that is called after stepping the simulation. Can be used
        to enforce additional constraints on the simulation state.
        """
        pass


class TwoRobotsEnvBBeckman(gym.GoalEnv):

    def __init__(self,
                 model_path,
                 initial_qpos,
                 n_actions,
                 n_sub_steps,
                 seed):

        self._load_model(model_path, n_sub_steps)

        self._set_up_rendering()

        self.np_random = 0  # shut up the IDE warning.
        self.seed(seed=seed)

        # [[[ bbeckman: 'initial_qpos' comes in via kwargs from gym.make
        # at top-level. For now, it's an empty dict, and initial qpos comes
        # from the modeling XML file in the assets directory. ]]]
        # [[[ bbeckman: one qpos for both targets ]]]
        self._env_setup(initial_qpos=initial_qpos)

        # [[[ bbeckman: TODO: why is this array of shape (76,)?
        # 24 joint + 7 cube(object) + 7 target == 38, once for each
        # side (audience-left == LEFT, audience-right == RIGHT)? ]]]
        # At the beginning of the sim, the values in this array should be
        # equal to those from the XML model. Check by manual inspection
        # (there is one automated check by 'assert' in _env_setup above).
        self.initial_state = copy.deepcopy(self.sim.get_state())

        # [[[ bbeckman: _sample_goal returns a "target" 7-vector qpos.
        # Unfortunately, we don't know why they use two different terms,
        # whether there is supposed to be some difference between "goal" and
        # "target," or whether having two terms is just an accident.
        self.goal = self._sample_goal()
        self.target_randomized = True

        # Notice that state is not changed.
        inspect_me = self.sim.get_state()
        np.array_equal(inspect_me, self.initial_state)

        self._set_up_space_boxes(n_actions)

    def _set_up_space_boxes(self, n_actions):
        obs = self._get_obs()
        # The 'observation' field of 'obs' has 48 pos + vel states for the
        # hand, then 13 ori + ori_vel states for the hand on audience left;
        # then the same thing for the hand on audience right. The right
        # hand ori begins at slot 109 = 61 + 48, and we're all done before
        # slot 122. Other fields in the obs support algorithms. We could
        # achieve custom fields for various applications by subclassing or by
        # monkey-patching, and it might be better to do so. Subclassing or
        # monkey-patching would afford us a clean, base-class environment.
        self.action_space = spaces.Box(-1., 1., shape=(n_actions,),
                                       dtype='float32')
        # [[[ bbeckman: The observation space appears not to be used. ]]]
        self.observation_space = spaces.Dict(dict(
            desired_goal=spaces.Box(
                -np.inf, np.inf,
                shape=obs['achieved_goal'].shape, dtype='float32'),
            achieved_goal=spaces.Box(
                -np.inf, np.inf,
                shape=obs['achieved_goal'].shape, dtype='float32'),
            observation=spaces.Box(
                -np.inf, np.inf, shape=obs['observation'].shape,
                dtype='float32'),
        ))

    def _set_up_rendering(self):
        self.viewer = None
        self._viewers = {}
        self.metadata = {
            'render.modes': ['human', 'rgb_array'],
            'video.frames_per_second': int(np.round(1.0 / self.dt))
        }

    def _load_model(self, model_path, n_sub_steps):
        if model_path.startswith('/'):
            full_path = model_path
        else:
            full_path = os.path.join(os.path.dirname(__file__), 'assets',
                                     model_path)
        if not os.path.exists(full_path):
            raise IOError('File {} does not exist'.format(full_path))
        model = mujoco_py.load_model_from_path(full_path)
        self.sim = mujoco_py.MjSim(model, nsubsteps=n_sub_steps)

    @property
    def dt(self):
        return self.sim.model.opt.timestep * self.sim.nsubsteps

    # Env methods
    # ----------------------------

    def seed(self, seed=None):
        self.np_random, seed = seeding.np_random(seed)
        return [seed]

    def _double_goal(self):
        """ bbeckman: TODO: hacky solution to one goal for both hands. """
        l = self.goal
        # TODO: violation code-review guideline 9: magic number 0.5!
        # [[[ bbeckman: TODO: if you change the separation between the
        # hands from 0.5 meters, you must change the XML files (search
        # for 1.5 in the 'assets' directory; there are several places).
        # That's one reason for leaving this glaring magic number 0.5. ]]]
        r = self.goal + [0.5, 0, 0, 0, 0, 0, 0]  # right-hand cube
        result = np.concatenate([l, r])
        return result

    def step(self, action):

        action = np.clip(action,
                         self.action_space.low,
                         self.action_space.high)

        self._set_action(action)
        self.sim.step()
        self._step_callback()

        obn = self._get_obs()

        done = False
        double_goal = self._double_goal()
        info = {
            'is_success': self._is_success(
                obn['achieved_goal'],  # [[[ bbeckman: already doubled ]]]
                double_goal),
        }
        reward = self.compute_reward(
            obn['achieved_goal'],
            double_goal,
            info)

        return obn, reward, done, info

    def reset(self, **kwargs):
        self._inspect_target()
        self._inspect_cube()

        # Random initial conditions might be invalid, e.g., penetration or
        # gimbal lock. Just keep randomizing until there is a valid initial
        # configuration.

        did_reset_sim = False
        while not did_reset_sim:
            did_reset_sim = self._reset_sim()
            if kwargs.get('always_the_same'):
                self.randomize_initial_position = False
                self.randomize_initial_rotation = False

        if not kwargs.get('always_the_same'):
            self.goal = self._sample_goal().copy()

        obs = self._get_obs()

        return obs

    def _inspect_cube(self):
        self._inspect_target()
        inspect = self.sim.get_state()
        inspec0 = self.sim.data.get_joint_qpos("object:joint")
        inspec1 = self.sim.data.get_joint_qpos("object_right:joint")
        # The first three elements of the joint qpos should equal the body xpos.
        # TODO: they do not maintain equality. Why not?
        inspec2 = self.sim.data.get_body_xpos("object")
        #  assert np.array_equal(inspec0[:3], inspec2)
        inspec3 = self.sim.data.get_body_xpos("object_right")
        #  assert np.array_equal(inspec1[:3], inspec3)
        return None

    def _inspect_target(self):
        inspec0 = self.sim.data.get_joint_qpos("target:joint")
        inspec1 = self.sim.data.get_joint_qpos("target_right:joint")
        # The first three elements of the joint qpos should equal the body xpos.
        # TODO: they do not maintain equality. Why not?
        inspec2 = self.sim.data.get_body_xpos("target")
        #  assert np.array_equal(inspec0[:3], inspec2)
        inspec3 = self.sim.data.get_body_xpos("target_right")
        #  assert np.array_equal(inspec1[:3], inspec3)
        return None

    def close(self):
        if self.viewer is not None:
            # self.viewer.finish()
            self.viewer = None
            self._viewers = {}

    def render(self, mode='human', width=DEFAULT_SIZE, height=DEFAULT_SIZE):
        self._render_callback()
        if mode == 'rgb_array':
            self._get_viewer(mode).render(width, height)
            # window size used for old mujoco-py:
            data = self._get_viewer(mode).read_pixels(width, height, depth=False)
            # original image is upside-down, so flip it
            return data[::-1, :, :]
        # [[[ bbeckman --- human mode is ignoring width and height. The ignoring
        # happens way down deep in the mujoco layer. mujoco_py.MjViewer ignores
        # the width and height from here and opens a window full-screen. ]]]
        elif mode == 'human':
            self._get_viewer(mode).render()

    def _get_viewer(self, mode):
        self.viewer = self._viewers.get(mode)
        if self.viewer is None:
            if mode == 'human':
                self.viewer = mujoco_py.MjViewer(self.sim)
            elif mode == 'rgb_array':
                self.viewer = mujoco_py.MjRenderContextOffscreen(self.sim, device_id=-1)
            self._viewer_setup()
            self._viewers[mode] = self.viewer
        return self.viewer

    # Extension methods
    # ----------------------------

    def _reset_sim(self):
        """Resets a simulation and indicates whether or not it was successful.
        If a reset was unsuccessful (e.g. if a randomized state caused an error
        in the simulation), this method should indicate such a failure by
        returning False. In such a case, this method will be called again to
        attempt the reset again.
        [[[ bbeckman: This docstring is out-of-date. ]]]
        """
        self.sim.set_state(self.initial_state)
        self.sim.forward()
        return True

    def _get_obs(self):
        """Returns the observation.
        """
        raise NotImplementedError()

    def _set_action(self, action):
        """Applies the given action to the simulation.
        """
        raise NotImplementedError()

    def _is_success(self, achieved_goal, desired_goal):
        """Indicates whether or not the achieved goal successfully achieved the desired goal.
        """
        raise NotImplementedError()

    def _sample_goal(self):
        """Samples a new goal and returns it.
        """
        raise NotImplementedError()

    def _env_setup(self, initial_qpos):
        """Initial configuration of the environment. Can be used to configure initial state
        and extract information from the simulation.
        """
        pass

    def _viewer_setup(self):
        """Initial configuration of the viewer. Can be used to set the camera
        position, for example.
        """
        pass

    def _render_callback(self):
        """A custom callback that is called before rendering. Can be used
        to implement custom visualizations.
        """
        pass

    def _step_callback(self):
        """A custom callback that is called after stepping the simulation. Can be used
        to enforce additional constraints on the simulation state.
        """
        pass
