import os
import numpy as np

from gym import utils, error
from gym.envs.robotics import rotations, hand_env
from gym.envs.robotics.utils import robot_get_obs

try:
    import mujoco_py
except ImportError as e:
    raise error.DependencyNotInstalled("{}. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)".format(e))


def quat_from_angle_and_axis(angle, axis):
    assert axis.shape == (3,)
    axis /= np.linalg.norm(axis)
    quat = np.concatenate([[np.cos(angle / 2.)], np.sin(angle / 2.) * axis])
    quat /= np.linalg.norm(quat)
    return quat


# Ensure we get the path separator correct on windows
MANIPULATE_BLOCK_XML = os.path.join('hand', 'manipulate_block.xml')
MANIPULATE_EGG_XML = os.path.join('hand', 'manipulate_egg.xml')
MANIPULATE_PEN_XML = os.path.join('hand', 'manipulate_pen.xml')


class ManipulateEnv(hand_env.HandEnv, utils.EzPickle):
    def __init__(
        self, model_path, target_position, target_rotation,
        target_position_range, reward_type, initial_qpos={},
        randomize_initial_position=True, randomize_initial_rotation=True,
        distance_threshold=0.01, rotation_threshold=0.1, n_substeps=20, relative_control=False,
        ignore_z_target_rotation=False,
    ):
        """Initializes a new Hand manipulation environment.

        Args:
            model_path (string): path to the environments XML file
            target_position (string): the type of target position:
                - ignore: target position is fully ignored, i.e. the object can be positioned arbitrarily
                - fixed: target position is set to the initial position of the object
                - random: target position is fully randomized according to target_position_range
            target_rotation (string): the type of target rotation:
                - ignore: target rotation is fully ignored, i.e. the object can be rotated arbitrarily
                - fixed: target rotation is set to the initial rotation of the object
                - xyz: fully randomized target rotation around the X, Y and Z axis
                - z: fully randomized target rotation around the Z axis
                - parallel: fully randomized target rotation around Z and axis-aligned rotation around X, Y
            ignore_z_target_rotation (boolean): whether or not the Z axis of the target rotation is ignored
            target_position_range (np.array of shape (3, 2)): range of the target_position randomization
            reward_type ('sparse' or 'dense'): the reward type, i.e. sparse or dense
            initial_qpos (dict): a dictionary of joint names and values that define the initial configuration
            randomize_initial_position (boolean): whether or not to randomize the initial position of the object
            randomize_initial_rotation (boolean): whether or not to randomize the initial rotation of the object
            distance_threshold (float, in meters): the threshold after which the position of a goal is considered achieved
            rotation_threshold (float, in radians): the threshold after which the rotation of a goal is considered achieved
            n_substeps (int): number of substeps the simulation runs on every call to step
            relative_control (boolean): whether or not the hand is actuated in absolute joint positions or relative to the current state
        """
        self.target_position = target_position
        self.target_rotation = target_rotation
        self.target_position_range = target_position_range
        self.parallel_quats = [rotations.euler2quat(r) for r in rotations.get_parallel_rotations()]
        self.randomize_initial_rotation = randomize_initial_rotation
        self.randomize_initial_position = randomize_initial_position
        self.distance_threshold = distance_threshold
        self.rotation_threshold = rotation_threshold
        self.reward_type = reward_type
        self.ignore_z_target_rotation = ignore_z_target_rotation

        assert self.target_position in ['ignore', 'fixed', 'random']
        assert self.target_rotation in ['ignore', 'fixed', 'xyz', 'z', 'parallel']

        hand_env.HandEnv.__init__(
            self, model_path, n_substeps=n_substeps, initial_qpos=initial_qpos,
            relative_control=relative_control)
        utils.EzPickle.__init__(self)

    def _get_achieved_goal(self):
        # Object position and rotation.
        object_qpos = self.sim.data.get_joint_qpos('object:joint')
        assert object_qpos.shape == (7,)
        return object_qpos

    def _goal_distance(self, goal_a, goal_b):
        assert goal_a.shape == goal_b.shape
        assert goal_a.shape[-1] == 7

        d_pos = np.zeros_like(goal_a[..., 0])
        d_rot = np.zeros_like(goal_b[..., 0])
        if self.target_position != 'ignore':
            delta_pos = goal_a[..., :3] - goal_b[..., :3]
            d_pos = np.linalg.norm(delta_pos, axis=-1)

        if self.target_rotation != 'ignore':
            quat_a, quat_b = goal_a[..., 3:], goal_b[..., 3:]

            if self.ignore_z_target_rotation:
                # Special case: We want to ignore the Z component of the rotation.
                # This code here assumes Euler angles with xyz convention. We first transform
                # to euler, then set the Z component to be equal between the two, and finally
                # transform back into quaternions.
                euler_a = rotations.quat2euler(quat_a)
                euler_b = rotations.quat2euler(quat_b)
                euler_a[2] = euler_b[2]
                quat_a = rotations.euler2quat(euler_a)

            # Subtract quaternions and extract angle between them.
            quat_diff = rotations.quat_mul(quat_a, rotations.quat_conjugate(quat_b))
            angle_diff = 2 * np.arccos(np.clip(quat_diff[..., 0], -1., 1.))
            d_rot = angle_diff
        assert d_pos.shape == d_rot.shape
        return d_pos, d_rot

    # GoalEnv methods
    # ----------------------------

    def compute_reward(self, achieved_goal, goal, info):
        if self.reward_type == 'sparse':
            success = self._is_success(achieved_goal, goal).astype(np.float32)
            return (success - 1.)
        else:
            d_pos, d_rot = self._goal_distance(achieved_goal, goal)
            # We weigh the difference in position to avoid that `d_pos` (in meters) is completely
            # dominated by `d_rot` (in radians).
            return -(10. * d_pos + d_rot)

    # RobotEnv methods
    # ----------------------------

    def _is_success(self, achieved_goal, desired_goal):
        d_pos, d_rot = self._goal_distance(achieved_goal, desired_goal)
        achieved_pos = (d_pos < self.distance_threshold).astype(np.float32)
        achieved_rot = (d_rot < self.rotation_threshold).astype(np.float32)
        achieved_both = achieved_pos * achieved_rot
        return achieved_both

    def _env_setup(self, initial_qpos):
        for name, value in initial_qpos.items():
            self.sim.data.set_joint_qpos(name, value)
        self.sim.forward()

    def _reset_sim(self):
        self.sim.set_state(self.initial_state)
        self.sim.forward()

        initial_qpos = self.sim.data.get_joint_qpos('object:joint').copy()
        initial_pos, initial_quat = initial_qpos[:3], initial_qpos[3:]
        assert initial_qpos.shape == (7,)
        assert initial_pos.shape == (3,)
        assert initial_quat.shape == (4,)
        initial_qpos = None

        # Randomization initial rotation.
        if self.randomize_initial_rotation:
            if self.target_rotation == 'z':
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = np.array([0., 0., 1.])
                offset_quat = quat_from_angle_and_axis(angle, axis)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation == 'parallel':
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = np.array([0., 0., 1.])
                z_quat = quat_from_angle_and_axis(angle, axis)
                parallel_quat = self.parallel_quats[self.np_random.randint(len(self.parallel_quats))]
                offset_quat = rotations.quat_mul(z_quat, parallel_quat)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation in ['xyz', 'ignore']:
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = self.np_random.uniform(-1., 1., size=3)
                offset_quat = quat_from_angle_and_axis(angle, axis)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation == 'fixed':
                pass
            else:
                raise error.Error('Unknown target_rotation option "{}".'.format(self.target_rotation))

        # Randomize initial position.
        if self.randomize_initial_position:
            if self.target_position != 'fixed':
                initial_pos += self.np_random.normal(size=3, scale=0.005)

        initial_quat /= np.linalg.norm(initial_quat)
        initial_qpos = np.concatenate([initial_pos, initial_quat])
        self.sim.data.set_joint_qpos('object:joint', initial_qpos)

        def is_on_palm():
            self.sim.forward()
            cube_middle_idx = self.sim.model.site_name2id('object:center')
            cube_middle_pos = self.sim.data.site_xpos[cube_middle_idx]
            is_on_palm = (cube_middle_pos[2] > 0.04)
            return is_on_palm

        # Run the simulation for a bunch of timesteps to let everything settle in.
        for _ in range(10):
            self._set_action(np.zeros(20))
            try:
                self.sim.step()
            except mujoco_py.MujocoException:
                return False
        return is_on_palm()

    def _sample_goal(self):
        # Select a goal for the object position.
        target_pos = None
        if self.target_position == 'random':
            assert self.target_position_range.shape == (3, 2)
            offset = self.np_random.uniform(self.target_position_range[:, 0], self.target_position_range[:, 1])
            assert offset.shape == (3,)
            target_pos = self.sim.data.get_joint_qpos('object:joint')[:3] + offset
        elif self.target_position in ['ignore', 'fixed']:
            target_pos = self.sim.data.get_joint_qpos('object:joint')[:3]
        else:
            raise error.Error('Unknown target_position option "{}".'.format(self.target_position))
        assert target_pos is not None
        assert target_pos.shape == (3,)

        # Select a goal for the object rotation.
        target_quat = None
        if self.target_rotation == 'z':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = np.array([0., 0., 1.])
            target_quat = quat_from_angle_and_axis(angle, axis)
        elif self.target_rotation == 'parallel':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = np.array([0., 0., 1.])
            target_quat = quat_from_angle_and_axis(angle, axis)
            parallel_quat = self.parallel_quats[self.np_random.randint(len(self.parallel_quats))]
            target_quat = rotations.quat_mul(target_quat, parallel_quat)
        elif self.target_rotation == 'xyz':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = self.np_random.uniform(-1., 1., size=3)
            target_quat = quat_from_angle_and_axis(angle, axis)
        elif self.target_rotation in ['ignore', 'fixed']:
            target_quat = self.sim.data.get_joint_qpos('object:joint')
        else:
            raise error.Error('Unknown target_rotation option "{}".'.format(self.target_rotation))
        assert target_quat is not None
        assert target_quat.shape == (4,)

        target_quat /= np.linalg.norm(target_quat)  # normalized quaternion
        goal = np.concatenate([target_pos, target_quat])
        return goal

    def _render_callback(self):
        # Assign current state to target object but offset a bit so that the actual object
        # is not obscured.
        goal = self.goal.copy()
        assert goal.shape == (7,)
        if self.target_position == 'ignore':
            # Move the object to the side since we do not care about its position.
            goal[0] += 0.15
        self.sim.data.set_joint_qpos('target:joint', goal)
        self.sim.data.set_joint_qvel('target:joint', np.zeros(6))

        if 'object_hidden' in self.sim.model.geom_names:
            hidden_id = self.sim.model.geom_name2id('object_hidden')
            self.sim.model.geom_rgba[hidden_id, 3] = 1.
        self.sim.forward()

    def _get_obs(self):
        robot_qpos, robot_qvel = robot_get_obs(self.sim)
        object_qvel = self.sim.data.get_joint_qvel('object:joint')
        achieved_goal = self._get_achieved_goal().ravel()  # this contains the object position + rotation
        observation = np.concatenate([robot_qpos, robot_qvel, object_qvel, achieved_goal])
        return {
            'observation': observation.copy(),
            'achieved_goal': achieved_goal.copy(),
            'desired_goal': self.goal.ravel().copy(),
        }


class HandBlockEnv(ManipulateEnv):
    def __init__(self, target_position='random', target_rotation='xyz', reward_type='sparse'):
        super(HandBlockEnv, self).__init__(
            model_path=MANIPULATE_BLOCK_XML, target_position=target_position,
            target_rotation=target_rotation,
            target_position_range=np.array([(-0.04, 0.04), (-0.06, 0.02), (0.0, 0.06)]),
            reward_type=reward_type)


class HandEggEnv(ManipulateEnv):
    def __init__(self, target_position='random', target_rotation='xyz', reward_type='sparse'):
        super(HandEggEnv, self).__init__(
            model_path=MANIPULATE_EGG_XML, target_position=target_position,
            target_rotation=target_rotation,
            target_position_range=np.array([(-0.04, 0.04), (-0.06, 0.02), (0.0, 0.06)]),
            reward_type=reward_type)


class HandPenEnv(ManipulateEnv):
    def __init__(self, target_position='random', target_rotation='xyz', reward_type='sparse'):
        super(HandPenEnv, self).__init__(
            model_path=MANIPULATE_PEN_XML, target_position=target_position,
            target_rotation=target_rotation,
            target_position_range=np.array([(-0.04, 0.04), (-0.06, 0.02), (0.0, 0.06)]),
            randomize_initial_rotation=False, reward_type=reward_type,
            ignore_z_target_rotation=True, distance_threshold=0.05)


class TwoHandsManipulateEnvBBeckman(hand_env.TwoHandsEnvBBeckman,
                                    utils.EzPickle):

    # [[[ bbeckman: position and orientation are called 'configuration
    # variables' or 'generalized coordinates' in the language of Lagrangian
    # mechanics. Normally, and for the robot, the shape of the configuration
    # variables is exactly the same as the shape of their velocities.
    # Therefore, we do not need two names for the shapes of the configuration
    # variables and for their velocities in the case of the robot. For the
    # cube, the configuration variables include a quaternion, which has one
    # more dimension than its velocity (but not one more degree of freedom),
    # so we need two names for the shapes of the cube states, one name for the
    # seven configuration variables and one name for their six velocities).
    #
    # TODO: violation code-review guideline 24: no config file!
    # TODO: move the following constants to a YAML or JSON config file.
    # ]]]

    ROBOT_CONFIGURATION_SHAPE = (24,)
    CUBE_CONFIGURATION_SHAPE = (7,)
    TWO_CUBE_CONFIGURATIONS_SHAPE = (14,)
    CUBE_VELOCITY_SHAPE = (6,)
    POS_CONFIGURATION_SHAPE = (3,)
    QUATERNION_CONFIGURATION_SHAPE = (4,)

    def __init__(
        self,
        model_path,
        target_position,
        target_rotation,
        target_position_range,
        reward_type,
        initial_qpos={},
        randomize_initial_position=True,
        randomize_initial_rotation=True,
        distance_threshold=0.01,
        rotation_threshold=0.1,
        n_sub_steps=20,
        relative_control=False,
        ignore_z_target_rotation=False,
    ):
        """Initializes a new Two-Hands manipulation environment. [[[ bbeckman:
        work-in-progress; subject to rapid and breaking changes without notice.
        ]]]

        Args:

            model_path (string): path to the environments XML file
            target_position (string): the type of target position:

                - "ignore": target position is fully ignored, i.e. the object
                  can be positioned arbitrarily

                - "fixed": target position is set to the initial position of
                  the object

                - "random": target position is fully randomized according to
                  target_position_range

            target_rotation (string): the type of target rotation:

                - "ignore": target rotation is fully ignored, i.e. the object
                  can be rotated arbitrarily

                - "fixed": target rotation is set to the initial rotation of
                  the object

                - "xyz": fully randomized target rotation around the X, Y and Z
                  axis

                - "z": fully randomized target rotation around the Z axis

                - "parallel": fully randomized target rotation around Z and
                  axis-aligned rotation around X, Y

            ignore_z_target_rotation (boolean): whether to ignore  the Z axis
            of the target rotation

            target_position_range (np.array of shape (3, 2)): range of the
            target_position randomization

            reward_type ('sparse' or 'dense'): the reward type, i.e. sparse or
            dense

            initial_qpos (dict): a dictionary of joint names and values that
            define the initial configuration

            randomize_initial_position (boolean): whether or not to randomize
            the initial position of the object

            randomize_initial_rotation (boolean): whether or not to randomize
            the initial rotation of the object

            distance_threshold (float, in meters): the threshold after which
            the position of a goal is considered achieved

            rotation_threshold (float, in radians): the threshold after which
            the rotation of a goal is considered achieved

            n_sub_steps (int): number of substeps the simulation runs on every
            call to step

            relative_control (boolean): whether to actuate the hand in absolute
            joint positions or relative to the current state

        """
        # [[[ bbeckman: modify for two targets.
        # First request is for two hands, identical targets. Just make two
        # copies of the existing, single target.
        # ]]]
        self.target_position = target_position
        self.target_rotation = target_rotation
        self.target_position_range = target_position_range
        self.parallel_quats = [rotations.euler2quat(r)
                               for r in rotations.get_parallel_rotations()]

        self.randomize_initial_rotation = randomize_initial_rotation
        self.randomize_initial_position = randomize_initial_position

        self.distance_threshold = distance_threshold
        self.rotation_threshold = rotation_threshold

        self.reward_type = reward_type
        self.ignore_z_target_rotation = ignore_z_target_rotation

        assert self.target_position in ['ignore', 'fixed', 'random']
        assert self.target_rotation in ['ignore', 'fixed', 'xyz', 'z', 'parallel']

        hand_env.TwoHandsEnvBBeckman.__init__(
            self,
            model_path,
            n_sub_steps=n_sub_steps,
            initial_qpos=initial_qpos,
            relative_control=relative_control)

        utils.EzPickle.__init__(self)

    def _get_achieved_goal(self):
        # Object position and rotation
        # [[[ bbeckman: position in the first three slots of 'qpos,' normalized
        #     quaternion in the last four slots. ]]]
        object_qpos = self.sim.data.get_joint_qpos('object:joint')
        assert object_qpos.shape == self.CUBE_CONFIGURATION_SHAPE
        object_right_qpos = self.sim.data.get_joint_qpos('object_right:joint')
        assert object_right_qpos.shape == self.CUBE_CONFIGURATION_SHAPE
        # return object_qpos
        # [[[ bbeckman: TODO: can't return the following till we fix up rewards etc. ]]]
        return np.concatenate([object_qpos, object_right_qpos])

    def _goal_distance(self, goal_a, goal_b):

        assert goal_a.shape == goal_b.shape
        assert goal_a.shape == self.CUBE_CONFIGURATION_SHAPE

        d_pos = np.zeros_like(goal_a[..., 0])
        d_rot = np.zeros_like(goal_b[..., 0])

        if self.target_position != 'ignore':
            delta_pos = goal_a[..., :3] - goal_b[..., :3]
            d_pos = np.linalg.norm(delta_pos, axis=-1)

        if self.target_rotation != 'ignore':
            quat_a, quat_b = goal_a[..., 3:], goal_b[..., 3:]

            if self.ignore_z_target_rotation:
                # Special case: Ignore Z component of rotation.
                # Assumes Euler angles with xyz convention. Transform
                # to euler, set Z component halfway between
                # the two, transform back into quaternions.
                euler_a = rotations.quat2euler(quat_a)
                euler_b = rotations.quat2euler(quat_b)
                euler_a[2] = euler_b[2]
                quat_a = rotations.euler2quat(euler_a)

            # Subtract quaternions; extract angle between
            quat_diff = rotations.quat_mul(quat_a, rotations.quat_conjugate(quat_b))
            angle_diff = 2 * np.arccos(np.clip(quat_diff[..., 0], -1., 1.))
            d_rot = angle_diff

        assert d_pos.shape == d_rot.shape

        return d_pos, d_rot

    def _goal_distances(self, attained, desired):

        assert attained.shape == desired.shape
        assert attained.shape == self.TWO_CUBE_CONFIGURATIONS_SHAPE

        goal_distance_left = self._goal_distance(
            attained[:self.CUBE_CONFIGURATION_SHAPE[0]],
            desired[:self.CUBE_CONFIGURATION_SHAPE[0]]
        )
        goal_distance_right = self._goal_distance(
            attained[self.CUBE_CONFIGURATION_SHAPE[0]:],
            desired[self.CUBE_CONFIGURATION_SHAPE[0]:]
        )

        result = (goal_distance_left, goal_distance_right)

        return result

    # GoalEnv methods
    # ----------------------------

    MAGIC_POSITION_WEIGHT = 10.

    def compute_reward(self, achieved_goal, goal, info):
        if self.reward_type == 'sparse':
            success = self._is_success(achieved_goal, goal).astype(np.float32)
            return success - 1.
        else:  # [[[ bbeckman: TODO: non-sparse rewards are definitely BROKEN!
            d_pos, d_rot = self._goal_distances(achieved_goal, goal)
            # weight the difference in position to avoid that `d_rot' in
            # radians completely dominates` `d_pos` (in meters).
            return -(self.MAGIC_POSITION_WEIGHT * d_pos + d_rot)

    # RobotEnv methods
    # ----------------------------

    def _is_success(self, achieved_goal, desired_goal):

        d_poss, d_rots = self._goal_distances(achieved_goal, desired_goal)

        achieved_left_pos = (d_poss[0] < self.distance_threshold).astype(np.float32)
        achieved_left_rot = (d_rots[0] < self.rotation_threshold).astype(np.float32)
        achieved_left_pose = achieved_left_pos * achieved_left_rot

        achieved_rigt_pos = (d_poss[1] < self.distance_threshold).astype(np.float32)
        achieved_rigt_rot = (d_rots[1] < self.rotation_threshold).astype(np.float32)
        achieved_rigt_pose = achieved_rigt_pos * achieved_rigt_rot

        result = achieved_left_pose or achieved_rigt_pose
        return result

    def _env_setup(self, initial_qpos):
        for name, value in initial_qpos.items():
            self.sim.data.set_joint_qpos(name, value)
        # [[[ bbeckman: TODO: hack ]]]
        self.sim.data.set_joint_qpos(
            "target_right:joint",
            self.sim.data.get_joint_qpos("target:joint") + [0.5, 0, 0, 0, 0, 0, 0]
        )
        self.sim.forward()

    # TODO: violation code-review guideline 23: dead code!
    # [[[ bbeckman: future proofing ]]]
    def _reset_cube_bbeckman(self):
        pass

    def _reset_sim(self):
        self.sim.set_state(self.initial_state)
        self.sim.forward()

        # [[[ bbeckman: TODO "object" is really "cube_left." Consider renaming.
        initial_qpos = self.sim.data.get_joint_qpos('object:joint').copy()
        initial_pos, initial_quat = initial_qpos[:3], initial_qpos[3:]

        assert initial_qpos.shape == self.CUBE_CONFIGURATION_SHAPE
        assert initial_pos.shape == self.POS_CONFIGURATION_SHAPE
        assert initial_quat.shape == self.QUATERNION_CONFIGURATION_SHAPE
        initial_qpos = None

        # [[[ bbeckman: TODO: this looks like copy-paste code, but where from? ]]]
        if self.randomize_initial_rotation:
            if self.target_rotation == 'z':
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = np.array([0., 0., 1.])
                offset_quat = quat_from_angle_and_axis(angle, axis)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation == 'parallel':
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = np.array([0., 0., 1.])
                z_quat = quat_from_angle_and_axis(angle, axis)
                parallel_quat = self.parallel_quats[self.np_random.randint(len(self.parallel_quats))]
                offset_quat = rotations.quat_mul(z_quat, parallel_quat)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation in ['xyz', 'ignore']:
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = self.np_random.uniform(-1., 1., size=3)
                offset_quat = quat_from_angle_and_axis(angle, axis)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation == 'fixed':
                pass
            else:
                raise error.Error('Unknown target_rotation option "{}".'.format(self.target_rotation))

        if self.randomize_initial_position:
            if self.target_position != 'fixed':
                initial_pos += self.np_random.normal(size=3, scale=0.005)

        initial_quat /= np.linalg.norm(initial_quat)
        # [[[ bbeckman: TODO: 'qpos' isn't a great name for pos + quat in that order ]]]
        initial_qpos = np.concatenate([initial_pos, initial_quat])
        self.sim.data.set_joint_qpos('object:joint', initial_qpos)

        def is_on_palm():
            self.sim.forward()
            cube_middle_idx = self.sim.model.site_name2id('object:center')
            cube_middle_pos = self.sim.data.site_xpos[cube_middle_idx]
            result = (cube_middle_pos[2] > 0.04)  # [[[ bbeckman: magic number ]]]
            return result

        # Run the simulation for a bunch of time steps to settle everything in.
        for _ in range(10):
            self._set_action(np.zeros(super().TWO_HANDS_ACTION_DIM))
            try:
                self.sim.step()
            except mujoco_py.MujocoException:
                return False
        # [[[ bbeckman: TODO will need to check left and right 'on_palm' ]]]
        return is_on_palm()

    def _sample_goal(self):

        # Select a goal for the object position.

        if self.target_position == 'random':
            assert self.target_position_range.shape == (3, 2)
            offset = self.np_random.uniform(self.target_position_range[:, 0],
                                            self.target_position_range[:, 1])
            assert offset.shape == (3,)
            target_pos = self.sim.data.get_joint_qpos('object:joint')[:3] + offset
        elif self.target_position in ['ignore', 'fixed']:
            target_pos = self.sim.data.get_joint_qpos('object:joint')[:3]
        else:
            raise error.Error('Unknown target_position option "{}".'.format(self.target_position))

        assert target_pos is not None
        assert target_pos.shape == self.POS_CONFIGURATION_SHAPE

        # Select a goal for the object rotation.

        if self.target_rotation == 'z':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = np.array([0., 0., 1.])
            target_quat = quat_from_angle_and_axis(angle, axis)
        elif self.target_rotation == 'parallel':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = np.array([0., 0., 1.])
            target_quat = quat_from_angle_and_axis(angle, axis)
            parallel_quat = self.parallel_quats[self.np_random.randint(len(self.parallel_quats))]
            target_quat = rotations.quat_mul(target_quat, parallel_quat)
        elif self.target_rotation == 'xyz':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = self.np_random.uniform(-1., 1., size=3)
            target_quat = quat_from_angle_and_axis(angle, axis)
        elif self.target_rotation in ['ignore', 'fixed']:
            target_quat = self.sim.data.get_joint_qpos('object:joint')
        else:
            raise error.Error('Unknown target_rotation option "{}".'.format(self.target_rotation))

        assert target_quat is not None
        assert target_quat.shape == self.QUATERNION_CONFIGURATION_SHAPE

        target_quat /= np.linalg.norm(target_quat)  # normalized quaternion
        goal = np.concatenate([target_pos, target_quat])
        return goal

    def _render_callback(self):
        # Assign current state to target object but offset a bit
        # so that the actual object is not obscured.
        goal = self.goal.copy()
        assert goal.shape == self.CUBE_CONFIGURATION_SHAPE
        if self.target_position == 'ignore':
            # Move the object to the side since we do not care about its position.
            goal[0] += 0.15
        self.sim.data.set_joint_qpos('target:joint', goal)
        self.sim.data.set_joint_qvel(
            'target:joint', np.zeros(self.CUBE_VELOCITY_SHAPE[0]))

        # [[[ bbeckman: TODO: hack ]]]
        self.sim.data.set_joint_qpos(
            "target_right:joint",
            self.sim.data.get_joint_qpos("target:joint") + [0.5, 0, 0, 0, 0, 0, 0]
        )
        self.sim.data.set_joint_qvel(
            'target_right:joint',
            self.sim.data.get_joint_qvel("target:joint")
        )

        # [[[ bbeckman: TODO: must worry about object_right's being hidden ]]]
        if 'object_hidden' in self.sim.model.geom_names:
            hidden_id = self.sim.model.geom_name2id('object_hidden')
            self.sim.model.geom_rgba[hidden_id, 3] = 1.
        self.sim.forward()

    def get_state(self):
        """[[[ bbeckman: Public version of _get_obs for bootstrapping
        controllers. ]]]"""
        return self._get_obs()

    def _get_obs(self):
        # [[[ bbeckman: new code here; changing things incrementally. "Left"
        # means from point-of-view of the camera, that is, the hand on the
        # left when you are looking at the screen. Likewise for "right." The
        # left robot is named "robot0" in the xml files in the assets folder.
        # ]]]
        robot_left_qpos, robot_left_qvel = robot_get_obs(self.sim, "robot0")
        assert robot_left_qpos.shape == robot_left_qvel.shape == \
            self.ROBOT_CONFIGURATION_SHAPE
        robot_left_state = np.concatenate([robot_left_qpos, robot_left_qvel])

        # [[[ bbeckman: "Rigt" is an abbreviation of "right" that has the same
        # number of letters as "left." This abbreviation makes code easier to
        # read by enhancing vertical alignment. I rarely use this abbreviation
        # outside of code because it might be confusing. The right robot is
        # named "robot1" in the xml files in the assets folder. ]]]
        robot_rigt_qpos, robot_rigt_qvel = robot_get_obs(self.sim, "robot1")
        assert robot_rigt_qpos.shape == robot_rigt_qvel.shape == \
            self.ROBOT_CONFIGURATION_SHAPE
        robot_rigt_state = np.concatenate([robot_rigt_qpos, robot_rigt_qvel])

        # [[[ bbeckman: "object" means "cube" in our current application. The
        # original reuses this code for manipulating the egg and for
        # manipulating the pen, so they use the word "object" so as to be less
        # specific. We retain that less specific name for now. ]]]
        object_left_qpos = self.sim.data.get_joint_qpos('object:joint')
        assert object_left_qpos.shape == self.CUBE_CONFIGURATION_SHAPE

        # [[[ bbeckman: To maximize reuse and to minimize disruption in the
        # XML files, I left the name of the cube on the left-hand side of the
        # screen as "object." The cube on the right-hand side of the screen is
        # called "object_right." The object coordinates are assumed to be (x,
        # y, z) and a 4D, normalized quaternion, which really only has three
        # degrees of freedom. "qpos" is, then 7D, 6DOF. ]]]
        object_rigt_qpos = self.sim.data.get_joint_qpos('object_right:joint')
        assert object_rigt_qpos.shape == self.CUBE_CONFIGURATION_SHAPE

        # [[[ bbeckman: velocity of the object is presumed to be (x_dot,
        # y_dot, z_dot, phi_roll_dot, theta_pitch_dot, psi_yaw_dot). In any
        # event, it's 6D with six degrees of freedom. ]]]
        object_left_qvel = self.sim.data.get_joint_qvel('object:joint')
        assert object_left_qvel.shape == self.CUBE_VELOCITY_SHAPE

        object_rigt_qvel = self.sim.data.get_joint_qvel('object_right:joint')
        assert object_rigt_qvel.shape == self.CUBE_VELOCITY_SHAPE

        object_left_state = np.concatenate([object_left_qpos, object_left_qvel])
        object_rigt_state = np.concatenate([object_rigt_qpos, object_rigt_qvel])

        achieved_goal = self._get_achieved_goal().ravel()

        observation = np.concatenate([
            robot_left_state,
            object_left_state,
            robot_rigt_state,
            object_rigt_state
        ])

        left_side = np.concatenate([
            robot_left_state.copy(),
            object_left_state.copy()
        ])
        left_side_shape = left_side.shape
        rigt_side = np.concatenate([
            robot_rigt_state.copy(),
            object_rigt_state.copy()
        ])
        rigt_side_shape = rigt_side.shape
        return {
            'observation': observation.copy(),
            'achieved_goal': achieved_goal.copy(),
            'desired_goal': self.goal.ravel().copy(),

            # TODO: violation of code-review guideline 12: code commented out!

            # 'left_robot_state': robot_left_state.copy(),
            # 'left_robot_state_shape': robot_left_state.shape,
            # 'right_robot_state': robot_rigt_state.copy(),
            # 'right_robot_state_shape': robot_rigt_state.shape,
            # 'left_object_state': object_left_state.copy(),
            # 'left_object_state_shape': object_left_state.shape,
            # 'right_object_state': object_rigt_state.copy(),
            # 'right_object_state_shape': object_rigt_state.shape,

            'left_side': left_side,
            'left_side_shape': left_side_shape,
            'rigt_side': rigt_side,
            'rigt_side_shape': rigt_side_shape,
        }


class TwoHandsBlockEnvBBeckman(TwoHandsManipulateEnvBBeckman):
    """[[[ bbeckman: This is the top-level environment, mapped through the
    registry to the name 'TwoHandsManipulateBlocks-v0' in envs/__init__.py,
    line 415.

    'gym.make("TwoHandsManipulateBlocks-v0")' calls this constructor
    through wrapper layers. TODO: do we need to change the wrappers?

    A copy so as not to derange the original.

    TwoHandsBlockEnvBBeckman is the most derived class.
    The class hierarchy follows:



                                   --
                                  ----
                                 ------
                                   ||
                        gym.ENV(top of hierarchy)
                                   /\
                                  is-a
                                   ||
                              gym.GoalEnv
                                   /\
                                  is-a
                                   ||
            gym.envs.robotics.robot_env.TwoRobotsEnvBBeckman
                                   /\
                                  is-a
                                   ||
             gym.envs.robotics.hand_envs.TwoHandsEnvBBeckman
                                   /\
                                  is-a
                                   ||
      gym.envs.robotics.hand.manipulate.TwoHandsManipulateEnvBBeckman
                                   /\
                                  is-a
                                   ||
        gym.envs.robotics.hand.manipulate.TwoHandsBlockEnvBBeckman
                                   /\
                                 calls
                                   ||
          envs.__init__:'gym.make("TwoHandsManipulateBlocks-v0")'



    -------------------- WITH METHOD OVERRIDES: ---------------------------

                                   --
                                  ----
                                 ------
                                   ||
                        gym.ENV(top of hierarchy)
                        =========================
        VIRT v  step(self, action):              # must impl
        VIRT v  reset(self):                     # must impl
        VIRT v  render(self, mode='human'):      # must impl
        IMPL *  close(self):                     # overridable default
        IMPL *  seed(self, seed=None):           # overridable default
                @property
        IMPL *  unwrapped(self):
                                   /\
                                  is-a
                                   ||
                              gym.GoalEnv
                              ===========
        DELE ^  reset(self)                      # checking, then super
        VIRT v  compute_reward(self, achieved, desired, info)    # must impl
                                   /\
                                  is-a
                                   ||
            gym.envs.robotics.robot_env.TwoRobotsEnvBBeckman
            ================================================
        OVER *  seed(self, seed=None):
        OVER *  step(self, action):
        OVER *  reset(self):
        OVER *  close(self):
        OVER *  render(self, mode='human', width=DEFAULT, height=DEFAULT):
        IMPL *  _get_viewer(self, mode):
                # Extension methods
                # ----------------------------
        IMPL *  _reset_sim(self):
        VIRT v  _get_obs(self):                  # must impl
        VIRT v  _set_action(self, action):       # must impl
        VIRT v  _is_success(self, achieved, desired):  # must impl
        VIRT v  _sample_goal(self):              # must impl
        VIRT v  _env_setup(self, initial_qpos):  # optional (pass)
        VIRt v  _viewer_setup(self):             # optional (pass)
        VIRT v  _render_callback(self):          # optional (pass)
        VIRT v  _step_callback(self):            # optional (pass)
                                   /\
                                  is-a
                                   ||
             gym.envs.robotics.hand_envs.TwoHandsEnvBBeckman
             ===============================================
        IMPL *  _set_action(self, action)
        IMPL *  _viewer_setup(self)
                                   /\
                                  is-a
                                   ||
      gym.envs.robotics.hand.manipulate.TwoHandsManipulateEnvBBeckman
      ===============================================================
        HLPR    _get_achieved_goal(self)
        HLPR    _goal_distance(self, goal_a, goal_b)
        NLPR    _goal_distances(self, attained, desired)
                # GoalEnv methods
                # ----------------------------
        IMPL *  compute_reward(self, achieved_goal, goal, info)
                # RobotEnv methods
                # ----------------------------
        OVER *  _is_success(self, achieved_goal, desired_goal)
        OVER *  _env_setup(self, initial_qpos)
                _reset_cube_bbeckman(self)       # dead code
        OVER *  _reset_sim(self)
        OVER *  _sample_goal(self)
        OVER *  _render_callback(self)
        IMPL *  get_state(self)                  # calls _get_obs
        OVER *  _get_obs(self)
                                   /\
                                  is-a
                                   ||
        gym.envs.robotics.hand.manipulate.TwoHandsBlockEnvBBeckman
        ==========================================================
        DELE ^  get_state(self)
                                   /\
                              instantiates
                                   ||
          envs.__init__:'gym.make("TwoHandsManipulateBlocks-v0")'
          =======================================================

    TODO: make this environment a subclass of ManipulateEnv rather than a copy.
    ]]]"""

    def __init__(self,
                 target_position='random',
                 target_rotation='xyz',
                 reward_type='sparse'):
        super(TwoHandsBlockEnvBBeckman, self).__init__(
            model_path=os.path.join('hand', 'two_hands_manipulate_blocks.xml'),
            target_position=target_position,
            target_rotation=target_rotation,
            target_position_range=np.array([(-0.04, 0.04), (-0.06, 0.02), (0.0, 0.06)]),
            reward_type=reward_type)
