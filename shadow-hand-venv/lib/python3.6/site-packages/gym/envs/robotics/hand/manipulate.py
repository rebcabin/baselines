import os
import numpy as np

from gym import utils, error
from gym.envs.robotics import rotations, hand_env
from gym.envs.robotics.utils import robot_get_obs

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

try:
    import mujoco_py
except ImportError as e:
    raise error.DependencyNotInstalled("{}. (HINT: you need to install mujoco_py, and also perform the setup instructions here: https://github.com/openai/mujoco-py/.)".format(e))


def quat_from_angle_and_axis(angle, axis):
    """bbeckman: Used quite a bit for initializing and sampling. TODO: consider
    moving to 'utils.'"""
    assert axis.shape == (3,)
    axis /= np.linalg.norm(axis)
    quat = np.concatenate([[np.cos(angle / 2.)], np.sin(angle / 2.) * axis])
    quat /= np.linalg.norm(quat)
    return quat


# Get correct path separator on Windows.
MANIPULATE_BLOCK_XML = os.path.join('hand', 'manipulate_block.xml')
MANIPULATE_EGG_XML = os.path.join('hand', 'manipulate_egg.xml')
MANIPULATE_PEN_XML = os.path.join('hand', 'manipulate_pen.xml')


class ManipulateEnv(hand_env.HandEnv, utils.EzPickle):
    def __init__(
        self, model_path, target_position, target_rotation,
        target_position_range, reward_type, initial_qpos={},
        randomize_initial_position=True, randomize_initial_rotation=True,
        distance_threshold=0.01, rotation_threshold=0.1, n_substeps=20, relative_control=False,
        ignore_z_target_rotation=False,
    ):
        """Initializes a new Hand manipulation environment.

        Args:
            model_path (string): path to the environments XML file
            target_position (string): the type of target position:
                - ignore: target position is fully ignored, i.e. the object can be positioned arbitrarily
                - fixed: target position is set to the initial position of the object
                - random: target position is fully randomized according to target_position_range
            target_rotation (string): the type of target rotation:
                - ignore: target rotation is fully ignored, i.e. the object can be rotated arbitrarily
                - fixed: target rotation is set to the initial rotation of the object
                - xyz: fully randomized target rotation around the X, Y and Z axis
                - z: fully randomized target rotation around the Z axis
                - parallel: fully randomized target rotation around Z and axis-aligned rotation around X, Y
            ignore_z_target_rotation (boolean): whether or not the Z axis of the target rotation is ignored
            target_position_range (np.array of shape (3, 2)): range of the target_position randomization
            reward_type ('sparse' or 'dense'): the reward type, i.e. sparse or dense
            initial_qpos (dict): a dictionary of joint names and values that define the initial configuration
            randomize_initial_position (boolean): whether or not to randomize the initial position of the object
            randomize_initial_rotation (boolean): whether or not to randomize the initial rotation of the object
            distance_threshold (float, in meters): the threshold after which the position of a goal is considered achieved
            rotation_threshold (float, in radians): the threshold after which the rotation of a goal is considered achieved
            n_substeps (int): number of substeps the simulation runs on every call to step
            relative_control (boolean): whether or not the hand is actuated in absolute joint positions or relative to the current state
        """
        self.target_position = target_position
        self.target_rotation = target_rotation
        self.target_position_range = target_position_range
        self.parallel_quats = [rotations.euler2quat(r) for r in rotations.get_parallel_rotations()]
        self.randomize_initial_rotation = randomize_initial_rotation
        self.randomize_initial_position = randomize_initial_position
        self.distance_threshold = distance_threshold
        self.rotation_threshold = rotation_threshold
        self.reward_type = reward_type
        self.ignore_z_target_rotation = ignore_z_target_rotation

        assert self.target_position in ['ignore', 'fixed', 'random']
        assert self.target_rotation in ['ignore', 'fixed', 'xyz', 'z', 'parallel']

        hand_env.HandEnv.__init__(
            self, model_path, n_substeps=n_substeps, initial_qpos=initial_qpos,
            relative_control=relative_control)
        utils.EzPickle.__init__(self)

    def _get_achieved_goal(self):
        # Object position and rotation.
        object_qpos = self.sim.data.get_joint_qpos('object:joint')
        assert object_qpos.shape == (7,)
        return object_qpos

    def _goal_distance(self, goal_a, goal_b):
        assert goal_a.shape == goal_b.shape
        assert goal_a.shape[-1] == 7

        d_pos = np.zeros_like(goal_a[..., 0])
        d_rot = np.zeros_like(goal_b[..., 0])
        if self.target_position != 'ignore':
            delta_pos = goal_a[..., :3] - goal_b[..., :3]
            d_pos = np.linalg.norm(delta_pos, axis=-1)

        if self.target_rotation != 'ignore':
            quat_a, quat_b = goal_a[..., 3:], goal_b[..., 3:]

            if self.ignore_z_target_rotation:
                # Special case: We want to ignore the Z component of the rotation.
                # This code here assumes Euler angles with xyz convention. We first transform
                # to euler, then set the Z component to be equal between the two, and finally
                # transform back into quaternions.
                euler_a = rotations.quat2euler(quat_a)
                euler_b = rotations.quat2euler(quat_b)
                euler_a[2] = euler_b[2]
                quat_a = rotations.euler2quat(euler_a)

            # Subtract quaternions and extract angle between them.
            quat_diff = rotations.quat_mul(quat_a, rotations.quat_conjugate(quat_b))
            angle_diff = 2 * np.arccos(np.clip(quat_diff[..., 0], -1., 1.))
            d_rot = angle_diff
        assert d_pos.shape == d_rot.shape
        return d_pos, d_rot

    # GoalEnv methods
    # ----------------------------

    def compute_reward(self, achieved_goal, goal, info):
        if self.reward_type == 'sparse':
            success = self._is_success(achieved_goal, goal).astype(np.float32)
            return (success - 1.)
        else:
            d_pos, d_rot = self._goal_distance(achieved_goal, goal)
            # We weigh the difference in position to avoid that `d_pos` (in meters) is completely
            # dominated by `d_rot` (in radians).
            return -(10. * d_pos + d_rot)

    # RobotEnv methods
    # ----------------------------

    def _is_success(self, achieved_goal, desired_goal):
        d_pos, d_rot = self._goal_distance(achieved_goal, desired_goal)
        achieved_pos = (d_pos < self.distance_threshold).astype(np.float32)
        achieved_rot = (d_rot < self.rotation_threshold).astype(np.float32)
        achieved_both = achieved_pos * achieved_rot
        return achieved_both

    def _env_setup(self, initial_qpos):
        for name, value in initial_qpos.items():
            self.sim.data.set_joint_qpos(name, value)
        self.sim.forward()

    def _reset_sim(self):
        self.sim.set_state(self.initial_state)
        self.sim.forward()

        initial_qpos = self.sim.data.get_joint_qpos('object:joint').copy()
        initial_pos, initial_quat = initial_qpos[:3], initial_qpos[3:]
        assert initial_qpos.shape == (7,)
        assert initial_pos.shape == (3,)
        assert initial_quat.shape == (4,)
        initial_qpos = None

        # Randomization initial rotation.
        if self.randomize_initial_rotation:
            if self.target_rotation == 'z':
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = np.array([0., 0., 1.])
                offset_quat = quat_from_angle_and_axis(angle, axis)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation == 'parallel':
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = np.array([0., 0., 1.])
                z_quat = quat_from_angle_and_axis(angle, axis)
                parallel_quat = self.parallel_quats[self.np_random.randint(len(self.parallel_quats))]
                offset_quat = rotations.quat_mul(z_quat, parallel_quat)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation in ['xyz', 'ignore']:
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = self.np_random.uniform(-1., 1., size=3)
                offset_quat = quat_from_angle_and_axis(angle, axis)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation == 'fixed':
                pass
            else:
                raise error.Error('Unknown target_rotation option "{}".'.format(self.target_rotation))

        # Randomize initial position.
        if self.randomize_initial_position:
            if self.target_position != 'fixed':
                initial_pos += self.np_random.normal(size=3, scale=0.005)

        initial_quat /= np.linalg.norm(initial_quat)
        initial_qpos = np.concatenate([initial_pos, initial_quat])
        self.sim.data.set_joint_qpos('object:joint', initial_qpos)

        def is_on_palm():
            self.sim.forward()
            cube_middle_idx = self.sim.model.site_name2id('object:center')
            cube_middle_pos = self.sim.data.site_xpos[cube_middle_idx]
            is_on_palm = (cube_middle_pos[2] > 0.04)
            return is_on_palm

        # Run the simulation for a bunch of timesteps to let everything settle in.
        for _ in range(10):
            self._set_action(np.zeros(20))
            try:
                self.sim.step()
            except mujoco_py.MujocoException:
                return False
        return is_on_palm()

    def _sample_goal(self):
        # Select a goal for the object position.
        target_pos = None
        if self.target_position == 'random':
            assert self.target_position_range.shape == (3, 2)
            offset = self.np_random.uniform(self.target_position_range[:, 0], self.target_position_range[:, 1])
            assert offset.shape == (3,)
            target_pos = self.sim.data.get_joint_qpos('object:joint')[:3] + offset
        elif self.target_position in ['ignore', 'fixed']:
            target_pos = self.sim.data.get_joint_qpos('object:joint')[:3]
        else:
            raise error.Error('Unknown target_position option "{}".'.format(self.target_position))
        assert target_pos is not None
        assert target_pos.shape == (3,)

        # Select a goal for the object rotation.
        target_quat = None
        if self.target_rotation == 'z':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = np.array([0., 0., 1.])
            target_quat = quat_from_angle_and_axis(angle, axis)
        elif self.target_rotation == 'parallel':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = np.array([0., 0., 1.])
            target_quat = quat_from_angle_and_axis(angle, axis)
            parallel_quat = self.parallel_quats[self.np_random.randint(len(self.parallel_quats))]
            target_quat = rotations.quat_mul(target_quat, parallel_quat)
        elif self.target_rotation == 'xyz':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = self.np_random.uniform(-1., 1., size=3)
            target_quat = quat_from_angle_and_axis(angle, axis)
        elif self.target_rotation in ['ignore', 'fixed']:
            target_quat = self.sim.data.get_joint_qpos('object:joint')
        else:
            raise error.Error('Unknown target_rotation option "{}".'.format(self.target_rotation))
        assert target_quat is not None
        assert target_quat.shape == (4,)

        target_quat /= np.linalg.norm(target_quat)  # normalized quaternion
        goal = np.concatenate([target_pos, target_quat])
        return goal

    def _render_callback(self):
        # Assign current state to target object but offset a bit so that the actual object
        # is not obscured.
        goal = self.goal.copy()
        assert goal.shape == (7,)
        if self.target_position == 'ignore':
            # Move the object to the side since we do not care about its position.
            goal[0] += 0.15
        self.sim.data.set_joint_qpos('target:joint', goal)
        self.sim.data.set_joint_qvel('target:joint', np.zeros(6))

        if 'object_hidden' in self.sim.model.geom_names:
            hidden_id = self.sim.model.geom_name2id('object_hidden')
            self.sim.model.geom_rgba[hidden_id, 3] = 1.
        self.sim.forward()

    def _get_obs(self):
        robot_qpos, robot_qvel = robot_get_obs(self.sim)
        object_qvel = self.sim.data.get_joint_qvel('object:joint')
        achieved_goal = self._get_achieved_goal().ravel()  # this contains the object position + rotation
        observation = np.concatenate([robot_qpos, robot_qvel, object_qvel, achieved_goal])
        return {
            'observation': observation.copy(),
            'achieved_goal': achieved_goal.copy(),
            'desired_goal': self.goal.ravel().copy(),
        }


class HandBlockEnv(ManipulateEnv):
    def __init__(self, target_position='random', target_rotation='xyz', reward_type='sparse'):
        super(HandBlockEnv, self).__init__(
            model_path=MANIPULATE_BLOCK_XML, target_position=target_position,
            target_rotation=target_rotation,
            target_position_range=np.array([(-0.04, 0.04), (-0.06, 0.02), (0.0, 0.06)]),
            reward_type=reward_type)


class HandEggEnv(ManipulateEnv):
    def __init__(self, target_position='random', target_rotation='xyz', reward_type='sparse'):
        super(HandEggEnv, self).__init__(
            model_path=MANIPULATE_EGG_XML, target_position=target_position,
            target_rotation=target_rotation,
            target_position_range=np.array([(-0.04, 0.04), (-0.06, 0.02), (0.0, 0.06)]),
            reward_type=reward_type)


class HandPenEnv(ManipulateEnv):
    def __init__(self, target_position='random', target_rotation='xyz', reward_type='sparse'):
        super(HandPenEnv, self).__init__(
            model_path=MANIPULATE_PEN_XML, target_position=target_position,
            target_rotation=target_rotation,
            target_position_range=np.array([(-0.04, 0.04), (-0.06, 0.02), (0.0, 0.06)]),
            randomize_initial_rotation=False, reward_type=reward_type,
            ignore_z_target_rotation=True, distance_threshold=0.05)


class TwoHandsManipulateEnvBBeckman(hand_env.TwoHandsEnvBBeckman,
                                    utils.EzPickle):

    """bbeckman: Cube state is seven-dimensional: 3D Cartesian [x y z] position
    concatenated to 4D normalized quaternion orientation: 'configuration
    variables' or 'generalized coordinates,' in Lagrangian jargon. The original
    code uses the words "position" and "qpos" to mean this seven-dimensional
    vector. It's a regrettable choice of name because it's ambiguous with
    Cartesian position.

    The quaternion part of the configuration variables has one more dimension
    than its degrees of freedom because the quaternion is normalized. The time
    derivative of the quaternion part has only three dimensions. Therefore the
    'generalized velocity' for the cube has six dimensions.

    In summary, for the cube:

    qpos is seven-dimensional
    qvel is six-dimensional

    For the robot, the Lagrangian generalized coordinates or configuration
    variables are twenty-four angles of hinge joints:

    1. two wrist joints, =WRJ1= and =WRJ0= (in reverse order, intentionally)
    2. four first-finger joints, =FFJ3= through =FFJ0= (reverse order)
    3. four middle-finger joints, =MFJ3= through =MFJ0= (reverse order)
    4. four ring-finger joints, =RFJ3= through =RFJ0= (reverse order)
    5. five little-finger joints, =LFJ4= through =LFJ0= (reverse order)
    6. five thumb joints, =THJ4= through =THJ0= (reverse order)

    The shape of the array of configuration variables is exactly the same as
    the shape of the array of the time derivatives of the configuration
    variables, called 'generalized velocities.'

    for the robot hand

    qpos is 24-dimensional
    qvel is 24-dimensional

    """

    # TODO: violation code-review guideline 21: duplicates in test_hand_0.py!
    # TODO: violation code-review guideline 24: move to config file!
    # TODO: move the following constants to a YAML or JSON config file.

    ROBOT_CONFIGURATION_SHAPE = (24,)
    CUBE_CONFIGURATION_SHAPE = (7,)  # incl dependent quaternion normalization
    TWO_CUBE_CONFIGURATIONS_SHAPE = (14,)
    CUBE_VELOCITY_SHAPE = (6,)
    POS_CONFIGURATION_SHAPE = (3,)
    QUATERNION_CONFIGURATION_SHAPE = (4,)
    CUBE_SLICER= CUBE_CONFIGURATION_SHAPE[0]
    LEFT = 0
    RIGHT = 1

    FINGERTIP_SITE_NAMES = [
        ['robot0:S_fftip',
         'robot0:S_mftip',
         'robot0:S_rftip',
         'robot0:S_lftip',
         'robot0:S_thtip',
         ],
        ['robot1:S_fftip',
         'robot1:S_mftip',
         'robot1:S_rftip',
         'robot1:S_lftip',
         'robot1:S_thtip',
         ]]
    FINGERTIP_DEBUG_VIZ_CUBIE_NAMES =[
        ['lfffingertip:box',
         'lmffingertip:box',
         'lrffingertip:box',
         'llffingertip:box',
         'lthfingertip:box',
        ],
        ['rfffingertip:box',
         'rmffingertip:box',
         'rrffingertip:box',
         'rlffingertip:box',
         'rthfingertip:box',
        ]]

    def __init__(
        self,
        model_path,
        target_position,
        target_rotation,
        target_position_range,
        reward_type,
        initial_qpos={},
        randomize_initial_position=True,
        randomize_initial_rotation=True,
        distance_threshold=0.01,
        rotation_threshold=0.1,
        n_sub_steps=20,
        relative_control=False,
        ignore_z_target_rotation=False,
    ):
        """Initializes a new Two-Hands manipulation environment. [[[ bbeckman:
        work-in-progress; subject to rapid and breaking changes without notice.
        ]]]

        Args:

            model_path (string): path to the environments XML file
            target_position (string): the type of target position:

                - "ignore": target position is fully ignored, i.e. the object
                  can be positioned arbitrarily

                - "fixed": target position is set to the initial position of
                  the object

                - "random": target position is fully randomized according to
                  target_position_range

            target_rotation (string): the type of target rotation:

                - "ignore": target rotation is fully ignored, i.e. the object
                  can be rotated arbitrarily

                - "fixed": target rotation is set to the initial rotation of
                  the object

                - "xyz": fully randomized target rotation around the X, Y and Z
                  axis

                - "z": fully randomized target rotation around the Z axis

                - "parallel": fully randomized target rotation around Z and
                  axis-aligned rotation around X, Y

            ignore_z_target_rotation (boolean): whether to ignore  the Z axis
            of the target rotation

            target_position_range (np.array of shape (3, 2)): range of the
            target_position randomization

            reward_type ('sparse' or 'dense'): the reward type, i.e. sparse or
            dense

            initial_qpos (dict): a dictionary of joint names and values that
            define the initial configuration

            randomize_initial_position (boolean): whether or not to randomize
            the initial position of the object

            randomize_initial_rotation (boolean): whether or not to randomize
            the initial rotation of the object

            distance_threshold (float, in meters): the threshold after which
            the position of a goal is considered achieved

            rotation_threshold (float, in radians): the threshold after which
            the rotation of a goal is considered achieved

            n_sub_steps (int): number of substeps the simulation runs on every
            call to step

            relative_control (boolean): whether to actuate the hand in absolute
            joint positions or relative to the current state

        """
        # [[[ bbeckman: modify for two targets.
        # First request is for two hands, identical targets. Just make two
        # copies of the existing, single target.
        # ]]]
        self.target_position = target_position
        self.target_rotation = target_rotation
        self.target_position_range = target_position_range
        self.parallel_quats = [rotations.euler2quat(r)
                               for r in rotations.get_parallel_rotations()]

        self.randomize_initial_rotation = randomize_initial_rotation
        self.randomize_initial_position = randomize_initial_position

        self.distance_threshold = distance_threshold
        self.rotation_threshold = rotation_threshold

        self.reward_type = reward_type
        self.ignore_z_target_rotation = ignore_z_target_rotation

        assert self.target_position in ['ignore', 'fixed', 'random']
        assert self.target_rotation in ['ignore', 'fixed', 'xyz', 'z', 'parallel']

        hand_env.TwoHandsEnvBBeckman.__init__(
            self,
            model_path,
            n_sub_steps=n_sub_steps,
            initial_qpos=initial_qpos,
            relative_control=relative_control)

        utils.EzPickle.__init__(self)

    def _get_achieved_goal(self):
        """Cube Cartesian [x y z] position in the first three slots of 'qpos,' 4D
        normalized quaternion in the last four slots of 'qpos.' The name
        'qpos' is regrettable because it suggests only position. But it's a
        generalized, abstract position in the Lagrangian sense, containing
        seven scalar quantities."""

        cube_qpos = self.sim.data.get_joint_qpos('object:joint')
        assert cube_qpos.shape == self.CUBE_CONFIGURATION_SHAPE

        cube_right_qpos = self.sim.data.get_joint_qpos('object_right:joint')
        assert cube_right_qpos.shape == self.CUBE_CONFIGURATION_SHAPE

        return np.concatenate([cube_qpos, cube_right_qpos])

    def _goal_distance(self, goal_a, goal_b):

        assert goal_a.shape == goal_b.shape
        assert goal_a.shape == self.CUBE_CONFIGURATION_SHAPE

        d_pos = np.zeros_like(goal_a[..., 0])
        d_rot = np.zeros_like(goal_b[..., 0])

        if self.target_position != 'ignore':
            delta_pos = goal_a[..., :3] - goal_b[..., :3]
            d_pos = np.linalg.norm(delta_pos, axis=-1)

        if self.target_rotation != 'ignore':
            quat_a, quat_b = goal_a[..., 3:], goal_b[..., 3:]

            if self.ignore_z_target_rotation:
                # Special case: Ignore Z component of rotation.
                # Assumes Euler angles with xyz convention. Transform
                # to euler, set Z component halfway between
                # the two, transform back into quaternions.
                euler_a = rotations.quat2euler(quat_a)
                euler_b = rotations.quat2euler(quat_b)
                euler_a[2] = euler_b[2]
                quat_a = rotations.euler2quat(euler_a)

            # Subtract quaternions; extract angle between two quats
            quat_diff = rotations.quat_mul(
                quat_a, rotations.quat_conjugate(quat_b))
            angle_diff = 2 * np.arccos(np.clip(quat_diff[..., 0], -1., 1.))

            d_rot = angle_diff

        assert d_pos.shape == d_rot.shape

        return d_pos, d_rot

    def _goal_distances(self, attained, desired):
        """bbeckman: added for HPL double cube."""
        assert attained.shape == desired.shape
        assert attained.shape == self.TWO_CUBE_CONFIGURATIONS_SHAPE

        goal_distance_left = self._goal_distance(
            attained[:self.CUBE_SLICER],
            desired[:self.CUBE_SLICER]
        )
        goal_distance_right = self._goal_distance(
            attained[self.CUBE_SLICER:],
            desired[self.CUBE_SLICER:]
        )

        result = (goal_distance_left, goal_distance_right)

        return result

    # GoalEnv methods
    # ----------------------------

    # violation code-review guideline 9: magic numbers!
    # violation code-review guideline 24: magic not in config file!
    MAGIC_POSITION_WEIGHT = 10.

    def compute_reward(self, achieved_goal, goal, info):
        if self.reward_type == 'sparse':
            success = self._is_success(achieved_goal, goal).astype(np.float32)
            return success - 1.
        else:  # [[[ bbeckman: TODO: non-sparse rewards are definitely BROKEN!
            d_pos, d_rot = self._goal_distances(achieved_goal, goal)
            # weight the difference in position to avoid that `d_rot' in
            # radians completely dominates` `d_pos` (in meters).
            return -(self.MAGIC_POSITION_WEIGHT * d_pos + d_rot)

    # RobotEnv methods
    # ----------------------------

    def _is_success(self, achieved_goal, desired_goal):

        d_poss, d_rots = self._goal_distances(achieved_goal, desired_goal)

        achieved_left_pos = (d_poss[0] <
                             self.distance_threshold).astype(np.float32)
        achieved_left_rot = (d_rots[0] <
                             self.rotation_threshold).astype(np.float32)
        achieved_left_pose = achieved_left_pos * achieved_left_rot

        achieved_rigt_pos = (d_poss[1] <
                             self.distance_threshold).astype(np.float32)
        achieved_rigt_rot = (d_rots[1] <
                             self.rotation_threshold).astype(np.float32)
        achieved_rigt_pose = achieved_rigt_pos * achieved_rigt_rot

        result = achieved_left_pose or achieved_rigt_pose
        return result

    def _env_setup(self, initial_qpos):
        for name, value in initial_qpos.items():
            self.sim.data.set_joint_qpos(name, value)
        # TODO: violation code-review guideline 9: magic number 0.5!
        # [[[ bbeckman: TODO: hack ]]]
        # [[[ bbeckman: TODO: if you change the separation between the
        # hands from 0.5 meters, you must change the XML files (search
        # for 1.5 in the 'assets' directory; there are several places).
        # That's one reason for leaving this glaring magic number 0.5. ]]]
        self.sim.data.set_joint_qpos(
            "target_right:joint",
            self.sim.data.get_joint_qpos("target:joint") + [0.5, 0, 0, 0, 0, 0, 0]
        )
        self.sim.forward()

    def _reset_sim(self):
        self.sim.set_state(self.initial_state)
        self.sim.forward()

        # [[[ bbeckman: TODO "object" is really "cube_left." Consider renaming.
        initial_qpos = self.sim.data.get_joint_qpos('object:joint').copy()
        initial_pos, initial_quat = initial_qpos[:3], initial_qpos[3:]

        assert initial_qpos.shape == self.CUBE_CONFIGURATION_SHAPE
        assert initial_pos.shape == self.POS_CONFIGURATION_SHAPE
        assert initial_quat.shape == self.QUATERNION_CONFIGURATION_SHAPE
        initial_qpos = None

        # [[[ bbeckman: TODO: copy-paste code code-review guideline #21 (CRG
        # 21), but where from? ]]]
        if self.randomize_initial_rotation:
            if self.target_rotation == 'z':
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = np.array([0., 0., 1.])
                offset_quat = quat_from_angle_and_axis(angle, axis)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation == 'parallel':
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = np.array([0., 0., 1.])
                z_quat = quat_from_angle_and_axis(angle, axis)
                parallel_quat = self.parallel_quats[self.np_random.randint(len(self.parallel_quats))]
                offset_quat = rotations.quat_mul(z_quat, parallel_quat)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation in ['xyz', 'ignore']:
                angle = self.np_random.uniform(-np.pi, np.pi)
                axis = self.np_random.uniform(-1., 1., size=3)
                offset_quat = quat_from_angle_and_axis(angle, axis)
                initial_quat = rotations.quat_mul(initial_quat, offset_quat)
            elif self.target_rotation == 'fixed':
                pass
            else:
                raise error.Error('Unknown target_rotation option "{}".'.format(self.target_rotation))

        if self.randomize_initial_position:
            if self.target_position != 'fixed':
                initial_pos += self.np_random.normal(size=3, scale=0.005)

        initial_quat /= np.linalg.norm(initial_quat)
        # [[[ bbeckman: TODO: 'qpos' is a regrettable name for pos + quat in
        # that order ]]]
        initial_qpos = np.concatenate([initial_pos, initial_quat])
        self.sim.data.set_joint_qpos('object:joint', initial_qpos)

        def is_on_palm():
            self.sim.forward()
            cube_middle_idx = self.sim.model.site_name2id('object:center')
            cube_middle_pos = self.sim.data.site_xpos[cube_middle_idx]
            result = (cube_middle_pos[2] > 0.04)  # [[[ bbeckman: magic number ]]]
            return result

        # Run the simulation for a bunch of time steps to settle everything in.
        for _ in range(10):
            self._set_action(np.zeros(super().TWO_HANDS_ACTION_DIM))
            try:
                self.sim.step()
            except mujoco_py.MujocoException:
                return False
        # [[[ bbeckman: TODO will need to check left and right 'on_palm' ]]]
        return is_on_palm()

    def _sample_goal(self):
        """Called when episode-length, in time steps or in wall-clock time, exceed set
         maxima. See 'envs.__init__.py' and 'time_limit.py' for ways to change
         the maxima."""

        # Select a goal for the object position.

        if self.target_position == 'random':
            assert self.target_position_range.shape == (3, 2)
            offset = self.np_random.uniform(self.target_position_range[:, 0],
                                            self.target_position_range[:, 1])
            assert offset.shape == (3,)
            target_pos = self.sim.data.get_joint_qpos('object:joint')[:3] + offset
        elif self.target_position in ['ignore', 'fixed']:
            target_pos = self.sim.data.get_joint_qpos('object:joint')[:3]
        else:
            raise error.Error('Unknown target_position option "{}".'.format(self.target_position))

        assert target_pos is not None
        assert target_pos.shape == self.POS_CONFIGURATION_SHAPE

        # Select a goal for the object rotation.

        # bbeckman: violation code-review guideline #21: copy-paste code!

        if self.target_rotation == 'z':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = np.array([0., 0., 1.])
            target_quat = quat_from_angle_and_axis(angle, axis)
        elif self.target_rotation == 'parallel':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = np.array([0., 0., 1.])
            target_quat = quat_from_angle_and_axis(angle, axis)
            parallel_quat = self.parallel_quats[self.np_random.randint(len(self.parallel_quats))]
            target_quat = rotations.quat_mul(target_quat, parallel_quat)
        elif self.target_rotation == 'xyz':
            angle = self.np_random.uniform(-np.pi, np.pi)
            axis = self.np_random.uniform(-1., 1., size=3)
            target_quat = quat_from_angle_and_axis(angle, axis)
        elif self.target_rotation in ['ignore', 'fixed']:
            target_quat = self.sim.data.get_joint_qpos('object:joint')
        else:
            raise error.Error('Unknown target_rotation option "{}".'.format(self.target_rotation))

        assert target_quat is not None
        assert target_quat.shape == self.QUATERNION_CONFIGURATION_SHAPE

        target_quat /= np.linalg.norm(target_quat)  # normalized quaternion
        goal = np.concatenate([target_pos, target_quat])
        return goal

    def _render_callback(self):
        # Assign current state to target object but offset a bit
        # so that the actual object is not obscured.
        goal = self.goal.copy()
        assert goal.shape == self.CUBE_CONFIGURATION_SHAPE
        if self.target_position == 'ignore':
            # Move target to the side because it's only a visual cue.
            goal[0] += 0.15
        self.sim.data.set_joint_qpos('target:joint', goal)
        self.sim.data.set_joint_qvel(
            'target:joint', np.zeros(self.CUBE_VELOCITY_SHAPE[0]))

        # [[[ bbeckman: TODO: hack ]]]
        # TODO: violation code-review guideline 9: magic number 0.5!
        # [[[ bbeckman: TODO: if you change the separation between the
        # hands from 0.5 meters, you must change the XML files (search
        # for 1.5 in the 'assets' directory; there are several places).
        # That's one reason for leaving this glaring magic number 0.5. ]]]

        self.sim.data.set_joint_qpos(
            "target_right:joint",
            self.sim.data.get_joint_qpos("target:joint") + [0.5, 0, 0, 0, 0, 0, 0]
        )
        self.sim.data.set_joint_qvel(
            'target_right:joint',
            self.sim.data.get_joint_qvel("target:joint")
        )

        # [[[ bbeckman: TODO: must worry about object_right's being hidden ]]]
        if 'object_hidden' in self.sim.model.geom_names:
            hidden_id = self.sim.model.geom_name2id('object_hidden')
            self.sim.model.geom_rgba[hidden_id, 3] = 1.
        self.sim.forward()

    def get_state(self):
        """bbeckman: Public version of _get_obs for bootstrapping controllers.
        This is used once only to get the state at the beginning of a run, and
        it exists only because the gym environment has 'helpers' that prevent
        calling of 'private' methods, that is, methods with underscores as the
        first character in their names. Without this method, an application
        would be required to step the simulation to get a state. We want to
        read the state before stepping the simulation. """
        return self._get_obs()

    def _loss_from_norms(self, d_pos, d_rot):
        """TODO: the code here is redundant with ...
        TODO: 'loss' is probably a lousy name for this quantity."""
        result = ((self.MAGIC_POSITION_WEIGHT * d_pos) + d_rot)
        return result

    @staticmethod
    def pos_from_pose(pose):
        return pose[:3]

    @staticmethod
    def quat_from_pose(pose):
        return pose[3:]

    @staticmethod
    def quat_diff(qa, qb):
        return rotations.quat_mul(qa, rotations.quat_conjugate(qb))

    @staticmethod
    def pose_from_pos_and_quat(pos, quat):
        """A pose is concat(pos, quat)."""
        result = np.concatenate([pos, quat])
        return result

    def pose_diff(self, pose1, pose2):
        """A pose is a concat(3-vector pos, 4-vector (normalized) quat)."""
        pos_diff = self.pos_from_pose(pose1) - self.pos_from_pose(pose2)
        qut_diff = self.quat_diff(self.quat_from_pose(pose1),
                                  self.quat_from_pose(pose2))
        result = self.pose_from_pos_and_quat(pos_diff, qut_diff)
        return result

    def left_pose_from_goal(self, goal):
        return goal[:self.CUBE_SLICER]

    def right_pose_from_goal(self, goal):
        return goal[self.CUBE_SLICER:]

    @staticmethod
    def goal_from_poses(left_pose, right_pose):
        result = np.concatenate([left_pose, right_pose])
        return result

    def goals_diff(self, goal1, goal2):
        """A goal is concat(left_pose, right_pose)."""

        left_pose1 = self.left_pose_from_goal(goal1)
        left_pose2 = self.left_pose_from_goal(goal2)
        left_diff = self.pose_diff(left_pose1, left_pose2)

        rigt_pose1 = self.right_pose_from_goal(goal1)
        rigt_pose2 = self.right_pose_from_goal(goal2)
        rigt_diff = self.pose_diff(rigt_pose1, rigt_pose2)

        result = self.goal_from_poses(left_diff, rigt_diff)

        return result

    def _cartesian_fingertip_world_positions(self, robot_name_prefix):

        debug_cubie_visualization_of_fingertip_positions = True

        lri = 1 if robot_name_prefix[-1] == "1" else 0

        tip_poss = [self.sim.data.get_site_xpos(
            self.FINGERTIP_SITE_NAMES[lri][j])
            for j in range(5)]

        if debug_cubie_visualization_of_fingertip_positions:
            for j in range(5):
                m = self.sim.model._body_name2id[
                    self.FINGERTIP_DEBUG_VIZ_CUBIE_NAMES[lri][j]]
                for i in range(3):
                    self.sim.model.body_pos[m][i] = tip_poss[j][i]

        return tip_poss

    def _get_obs(self):
        # [[[ bbeckman: "Left" means from point-of-view of the camera, that
        # is, the hand on the left when you are looking at the screen.
        # Likewise for "right." The left robot is named "robot0" in the XML
        # files in the assets folder. ]]]
        robot_left_qpos, robot_left_qvel = robot_get_obs(self.sim, "robot0")
        assert robot_left_qpos.shape == robot_left_qvel.shape == \
            self.ROBOT_CONFIGURATION_SHAPE
        robot_left_state = np.concatenate([robot_left_qpos, robot_left_qvel])

        # [[[ bbeckman: "Rigt" is an abbreviation of "right." It has the same
        # number of letters as "left." The abbreviation enhances vertical
        # alignment in the code. I rarely use this abbreviation outside of
        # code because it might be confusing. The right robot is named
        # "robot1" in the XML files in the assets folder. ]]]
        robot_rigt_qpos, robot_rigt_qvel = robot_get_obs(self.sim, "robot1")
        assert robot_rigt_qpos.shape == robot_rigt_qvel.shape == \
            self.ROBOT_CONFIGURATION_SHAPE
        robot_rigt_state = np.concatenate([robot_rigt_qpos, robot_rigt_qvel])

        # [[[ bbeckman: "object" means "cube." The original reuses cube code
        # for manipulating the egg and for manipulating the pen, so they use
        # the word "object" so as to be less specific. We retain that less
        # specific name for now. ]]]
        object_left_qpos = self.sim.data.get_joint_qpos('object:joint')
        assert object_left_qpos.shape == self.CUBE_CONFIGURATION_SHAPE

        # [[[ bbeckman: The name of the cube on the left-hand side of the
        # screen is "object." The cube on the right-hand side of the screen is
        # "object_right." The object coordinates are assumed to be (x, y, z)
        # concatenated to a 4D, normalized quaternion, which really only has
        # three degrees of freedom. "qpos" is, then 7D, 6DOF. ]]]
        object_rigt_qpos = self.sim.data.get_joint_qpos('object_right:joint')
        assert object_rigt_qpos.shape == self.CUBE_CONFIGURATION_SHAPE

        # [[[ bbeckman: velocity of the object is presumed to be (x_dot,
        # y_dot, z_dot, phi_roll_dot, theta_pitch_dot, psi_yaw_dot), 6D, 6DOF.
        # ]]]
        object_left_qvel = self.sim.data.get_joint_qvel('object:joint')
        assert object_left_qvel.shape == self.CUBE_VELOCITY_SHAPE

        object_rigt_qvel = self.sim.data.get_joint_qvel('object_right:joint')
        assert object_rigt_qvel.shape == self.CUBE_VELOCITY_SHAPE

        object_left_state = np.concatenate([object_left_qpos, object_left_qvel])
        object_rigt_state = np.concatenate([object_rigt_qpos, object_rigt_qvel])

        # TODO: The following calculations are too complex and also redundant
        #  (inherited from original code)

        # TODO: violation code-review guideline 21: copy-paste code

        # TODO: these are raveled. Unravel everywhere?

        # Informal (non-machine checked) types:
        # A goal has type: concat(left_pose, right_pose).
        # A pose has type: concat(pos, quat).
        # A pos is three position components: x, y, z.
        # A quat is four components: w, x, y, z, Euclidean normalized,
        #   so the components are not independent; there are only three
        #   degrees of freedom.

        achieved_goal = self._get_achieved_goal()
        desired_goal = self._double_goal()  # robot_env.TwoRobotsEnvBBeckman
        residuals = self.goals_diff(desired_goal, achieved_goal)

        left_pose_norms, rigt_pose_norms = \
            self._goal_distances(achieved_goal, desired_goal)

        # Norms is a pair of scalars, one for the distance, one for the
        # quaternion component of a "distance."

        left_loss = self._loss_from_norms(*left_pose_norms)
        rigt_loss = self._loss_from_norms(*rigt_pose_norms)

        # Loss is a lousy name because it's ambiguous with a different meaning
        # from machine learning. However, here it means "how far away from the
        # goal are you?" It's a "cost" or "penalty."

        observation = np.concatenate([
            robot_left_state,
            object_left_state,
            robot_rigt_state,
            object_rigt_state
        ])

        left_side = np.concatenate([
            robot_left_state.copy(),
            object_left_state.copy()
        ])

        rigt_side = np.concatenate([
            robot_rigt_state.copy(),
            object_rigt_state.copy()
        ])

        result = {
            'observation': observation.copy(),
            'achieved_goal': achieved_goal.copy(),
            'desired_goal': desired_goal.copy(),

            # TODO: violation of code-review guideline 12: code commented out!
            # [[[ bbeckman: this paid off as i changed the code. ]]]

            # 'left_robot_state': robot_left_state.copy(),
            # 'left_robot_state_shape': robot_left_state.shape,
            # 'right_robot_state': robot_rigt_state.copy(),
            # 'right_robot_state_shape': robot_rigt_state.shape,

            'left_object_state': object_left_state.copy(),
            'right_object_state': object_rigt_state.copy(),

            # For 'test_hands_0.py'
            # TODO: unravel everywhere?
            'left_residual': residuals[:self.CUBE_SLICER],
            'rigt_residual': residuals[self.CUBE_SLICER:],

            # for autograder
            'left_loss': left_loss,
            'rigt_loss': rigt_loss,

            # For 'test_hands_1.py' only
            'left_side': left_side,
            # 'left_side_shape': left_side_shape,
            'rigt_side': rigt_side,
            # 'rigt_side_shape': rigt_side_shape,

            'left_cartesian_fingertip_world_positions':
                self._cartesian_fingertip_world_positions("robot0"),
            'rigt_cartesian_fingertip_world_positions':
                self._cartesian_fingertip_world_positions("robot1"),
        }
        return result  # set debugger breakpoint here


class TwoHandsBlockEnvBBeckman(TwoHandsManipulateEnvBBeckman):
    """bbeckman: This is the top-level environment, mapped through the
    registry to the name 'TwoHandsManipulateBlocks-v0' in envs/__init__.py,
    line 415. The application, e.g., "test_hand_0.py," gets an instance
    of this and assigns it to the variable "env."

    'gym.make("TwoHandsManipulateBlocks-v0")' calls this constructor
    through wrapper layers. TODO: do we need to change the wrappers?

    A copy so as not to derange the original.

    TwoHandsBlockEnvBBeckman is the most derived class.
    The class hierarchy follows:



                                   --
                                  ----
                                 ------
                                   ||
                        gym.ENV(top of hierarchy)
                                   /\
                                  is-a
                                   ||
                              gym.GoalEnv
                                   /\
                                  is-a
                                   ||
            gym.envs.robotics.robot_env.TwoRobotsEnvBBeckman
             (.sim attribute in this class points to mujoco)
                                   /\
                                  is-a
                                   ||
             gym.envs.robotics.hand_envs.TwoHandsEnvBBeckman
                                   /\
                                  is-a
                                   ||
      gym.envs.robotics.hand.manipulate.TwoHandsManipulateEnvBBeckman
                                   /\
                                  is-a
                                   ||
        gym.envs.robotics.hand.manipulate.TwoHandsBlockEnvBBeckman
                                   /\
                              instantiates
                                   ||
          envs.__init__:'gym.make("TwoHandsManipulateBlocks-v0")'



    -------------------- WITH METHOD OVERRIDES: ---------------------------

                                   --
                                  ----
                                 ------
                                   ||
                        gym.ENV(top of hierarchy)
                        =========================
        VIRT v  step(self, action):              # must impl
        VIRT v  reset(self):                     # must impl
        VIRT v  render(self, mode='human'):      # must impl
        IMPL *  close(self):                     # overridable default
        IMPL *  seed(self, seed=None):           # overridable default
                @property
        IMPL *  unwrapped(self):
                                   /\
                                  is-a
                                   ||
                              gym.GoalEnv
                              ===========
        DELE ^  reset(self)                      # checking, then super
        VIRT v  compute_reward(self, achieved, desired, info)    # must impl
                                   /\
                                  is-a
                                   ||
            gym.envs.robotics.robot_env.TwoRobotsEnvBBeckman
            ================================================
        This class has the .sim attribute pointing into mujoco.

        OVER *  seed(self, seed=None):
        HLPR    _double_goal(self)               # two hands, one goal
        OVER *  step(self, action):
        OVER *  reset(self):
        OVER *  close(self):
        OVER *  render(self, mode='human', width=DEFAULT, height=DEFAULT):
        IMPL *  _get_viewer(self, mode):
                # Extension methods
                # ----------------------------
        IMPL *  _reset_sim(self):                # default impl
        VIRT v  _get_obs(self):                  # must impl
        VIRT v  _set_action(self, action):       # must impl
        VIRT v  _is_success(self, achieved, desired):  # must impl
        VIRT v  _sample_goal(self):              # must impl
        VIRT v  _env_setup(self, initial_qpos):  # optional (pass)
        VIRt v  _viewer_setup(self):             # optional (pass)
        VIRT v  _render_callback(self):          # optional (pass)
        VIRT v  _step_callback(self):            # optional (pass)
                                   /\
                                  is-a
                                   ||
             gym.envs.robotics.hand_envs.TwoHandsEnvBBeckman
             ===============================================
        IMPL *  _set_action(self, action)
        IMPL *  _viewer_setup(self)
                                   /\
                                  is-a
                                   ||
      gym.envs.robotics.hand.manipulate.TwoHandsManipulateEnvBBeckman
      ===============================================================
      One of the wrappers prevents calls to methods whose names begin
      with underscore. Can't call _get_obs (presumably it's intended
      only for inside "env.step," so I created a proxy, "get_state,
      that applications can call.

        HLPR    _get_achieved_goal(self)
        HLPR    _goal_distance(self, goal_a, goal_b)
        HLPR    _goal_distances(self, attained, desired)
                # GoalEnv methods
                # ----------------------------
        IMPL *  compute_reward(self, achieved_goal, goal, info)
                # RobotEnv methods
                # ----------------------------
        OVER *  _is_success(self, achieved_goal, desired_goal)
        OVER *  _env_setup(self, initial_qpos)
                _reset_cube_bbeckman(self)       # dead code
        OVER *  _reset_sim(self)
        OVER *  _sample_goal(self)
        OVER *  _render_callback(self)
        IMPL *  get_state(self)                  # _get_obs proxy
        OVER *  _get_obs(self)                   # can't call this
                                   /\
                                  is-a
                                   ||
        gym.envs.robotics.hand.manipulate.TwoHandsBlockEnvBBeckman
        ==========================================================
        DELE ^  get_state(self)
                                   /\
                              instantiates
                                   ||
          envs.__init__:'gym.make("TwoHandsManipulateBlocks-v0")'
          =======================================================

    TODO: violation code-review guideline 21: duplicated code!
    TODO: make this environment a subclass of ManipulateEnv rather than a
    copy."""

    def __init__(self,
                 target_position='random',
                 target_rotation='xyz',
                 reward_type='sparse'):

        super(TwoHandsBlockEnvBBeckman, self).__init__(
            model_path=os.path.join('hand', 'two_hands_manipulate_blocks.xml'),
            target_position=target_position,
            target_rotation=target_rotation,
            target_position_range=np.array([(-0.04, 0.04), (-0.06, 0.02), (0.0, 0.06)]),
            reward_type=reward_type)
